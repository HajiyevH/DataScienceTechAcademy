{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler , RobustScaler\n",
    "from scipy.stats import boxcox,skew\n",
    "from sklearn.linear_model import LogisticRegression ,LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df = pd.read_csv(\"/Users/hajiaga/Downloads/creditcard.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-73477.0, -4.274396001792603, -2.7019605905224315, -3.7667054090861836, -3.236612225031064, -2.646882336821933, -2.51858636568538, -2.240843806907704, -1.0125931529838397, -2.503452471089882, -2.0194494839425694, -3.015625599764853, -1.941285763020238, -2.6151056869463822, -1.803659804964707, -2.430441907369377, -1.955036385495261, -1.8088832582431966, -1.9983346169934264, -1.8291713305051371, -0.7288646731770594, -0.8505531720141558, -2.148706384652634, -0.6260789583212862, -1.5457552412760254, -1.318935979464254, -1.178888075273932, -0.3136665027898834, -0.24981941467918245, -101.7475, 0.0]\n",
      "[266999.0, 4.669664311280146, 2.90713454829761, 3.9035361133965982, 3.1313133981683787, 2.5672117056694685, 2.148855653580996, 2.2572040007487804, 1.1313092708678223, 2.457493931105559, 1.9379472025887527, 2.9927248115734812, 2.1539523105259604, 2.629071347271788, 1.8712356417278626, 2.496378434529079, 2.010295931257707, 1.7248099271865331, 2.0002915652156013, 1.8318217675233686, 0.6501841494971068, 0.8085354286142143, 2.1349096473259586, 0.6118746771624517, 1.630695705034713, 1.3525064882663698, 1.092856323107968, 0.333872093171221, 0.27513957642002174, 184.5125, 0.0]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 274329 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    274329 non-null  float64\n",
      " 1   V1      274329 non-null  float64\n",
      " 2   V2      274329 non-null  float64\n",
      " 3   V3      274329 non-null  float64\n",
      " 4   V4      274329 non-null  float64\n",
      " 5   V5      274329 non-null  float64\n",
      " 6   V6      274329 non-null  float64\n",
      " 7   V7      274329 non-null  float64\n",
      " 8   V8      274329 non-null  float64\n",
      " 9   V9      274329 non-null  float64\n",
      " 10  V10     274329 non-null  float64\n",
      " 11  V11     274329 non-null  float64\n",
      " 12  V12     274329 non-null  float64\n",
      " 13  V13     274329 non-null  float64\n",
      " 14  V14     274329 non-null  float64\n",
      " 15  V15     274329 non-null  float64\n",
      " 16  V16     274329 non-null  float64\n",
      " 17  V17     274329 non-null  float64\n",
      " 18  V18     274329 non-null  float64\n",
      " 19  V19     274329 non-null  float64\n",
      " 20  V20     274329 non-null  float64\n",
      " 21  V21     274329 non-null  float64\n",
      " 22  V22     274329 non-null  float64\n",
      " 23  V23     274329 non-null  float64\n",
      " 24  V24     274329 non-null  float64\n",
      " 25  V25     274329 non-null  float64\n",
      " 26  V26     274329 non-null  float64\n",
      " 27  V27     274329 non-null  float64\n",
      " 28  V28     274329 non-null  float64\n",
      " 29  Amount  274329 non-null  float64\n",
      " 30  Class   274329 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284801    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 274329, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code which is fully written me and mentor\n",
    "\n",
    "def get_outliers(data , column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - IQR*1.5\n",
    "    upper_bound = Q3 + IQR*1.5\n",
    "    return [data.loc[(data[column].astype(float) < lower_bound) | (data[column].astype(float) > upper_bound)].shape[0] , lower_bound ,upper_bound]\n",
    "\n",
    "lowers , uppers = [] , []\n",
    "for col in df.columns:\n",
    "    lowers.append(get_outliers(df,col)[1])\n",
    "    uppers.append(get_outliers(df,col)[2])\n",
    "print(lowers)\n",
    "print(uppers)\n",
    "np.sum((df>lowers) & ( df<uppers),axis=1)>8\n",
    "df = df[np.sum((df>lowers) & ( df<uppers),axis=1)>23]\n",
    "df.info()\n",
    "df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_with_bounds(data):\n",
    "    for column in data.columns:\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        if column != \"Class\":\n",
    "            data[column] = np.where(data[column] < lower_bound, lower_bound, data[column])\n",
    "            data[column] = np.where(data[column] > upper_bound, upper_bound, data[column])\n",
    "    return data\n",
    "df = replace_outliers_with_bounds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     fig , (bfr , aft) = plt.subplots(nrows=1,ncols=2,figsize=(15,3))\n",
    "#     sns.histplot(df[col] , ax=bfr)\n",
    "#     sns.histplot(df[col].apply(np.log1p) , ax=aft)\n",
    "#     bfr.set(title= col)\n",
    "#     aft.set(title=\"Buda sonraki\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = df.dtypes[df.dtypes != \"object\"].index\n",
    "skewed_feats = df[num_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "skewed_feats =skewness[skewness>0.70].index\n",
    "for i in skewed_feats:\n",
    "    if i != \"Class\":\n",
    "        df[col] +=1\n",
    "        df[col] , lam = boxcox(df[col])\n",
    "\n",
    "df.select_dtypes(include=\"O\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/HajiyevH/DataScienceTechAcademy/frauddetetct.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://github/HajiyevH/DataScienceTechAcademy/frauddetetct.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=2'>3</a>\u001b[0m X_tr , X_te , Y_tr , Y_te  \u001b[39m=\u001b[39m train_test_split(df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), df[\u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://github/HajiyevH/DataScienceTechAcademy/frauddetetct.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=3'>4</a>\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(StandardScaler(),LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://github/HajiyevH/DataScienceTechAcademy/frauddetetct.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=5'>6</a>\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X_tr,Y_tr)\n\u001b[1;32m      <a href='vscode-notebook-cell://github/HajiyevH/DataScienceTechAcademy/frauddetetct.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(r2_score(Y_tr,pipeline\u001b[39m.\u001b[39mpredict(X_tr)))\n\u001b[1;32m      <a href='vscode-notebook-cell://github/HajiyevH/DataScienceTechAcademy/frauddetetct.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(r2_score(Y_te,pipeline\u001b[39m.\u001b[39mpredict(X_te)))\n",
      "File \u001b[0;32m~/anaconda3/envs/unsupervisedLearning/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsupervisedLearning/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsupervisedLearning/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsupervisedLearning/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1215\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m   1207\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1208\u001b[0m     X,\n\u001b[1;32m   1209\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39msolver \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1214\u001b[0m )\n\u001b[0;32m-> 1215\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n\u001b[1;32m   1218\u001b[0m multi_class \u001b[39m=\u001b[39m _check_multi_class(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmulti_class, solver, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_))\n",
      "File \u001b[0;32m~/anaconda3/envs/unsupervisedLearning/lib/python3.11/site-packages/sklearn/utils/multiclass.py:215\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    207\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[1;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m ]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    216\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "#model qurmaq\n",
    "\n",
    "X_tr , X_te , Y_tr , Y_te  = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=0.2, random_state=42, shuffle=True)\n",
    "pipeline = make_pipeline(StandardScaler(),LogisticRegression(random_state=42))\n",
    "\n",
    "pipeline.fit(X_tr,Y_tr)\n",
    "\n",
    "print(r2_score(Y_tr,pipeline.predict(X_tr)))\n",
    "print(r2_score(Y_te,pipeline.predict(X_te)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervisedLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
