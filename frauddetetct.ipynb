{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler , RobustScaler\n",
    "from scipy.stats import boxcox,skew\n",
    "from sklearn.linear_model import LogisticRegression ,LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df = pd.read_csv(\"/Users/hajiaga/Downloads/creditcard.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-73477.0, -4.274396001792603, -2.7019605905224315, -3.7667054090861836, -3.236612225031064, -2.646882336821933, -2.51858636568538, -2.240843806907704, -1.0125931529838397, -2.503452471089882, -2.0194494839425694, -3.015625599764853, -1.941285763020238, -2.6151056869463822, -1.803659804964707, -2.430441907369377, -1.955036385495261, -1.8088832582431966, -1.9983346169934264, -1.8291713305051371, -0.7288646731770594, -0.8505531720141558, -2.148706384652634, -0.6260789583212862, -1.5457552412760254, -1.318935979464254, -1.178888075273932, -0.3136665027898834, -0.24981941467918245, -101.7475, 0.0]\n",
      "[266999.0, 4.669664311280146, 2.90713454829761, 3.9035361133965982, 3.1313133981683787, 2.5672117056694685, 2.148855653580996, 2.2572040007487804, 1.1313092708678223, 2.457493931105559, 1.9379472025887527, 2.9927248115734812, 2.1539523105259604, 2.629071347271788, 1.8712356417278626, 2.496378434529079, 2.010295931257707, 1.7248099271865331, 2.0002915652156013, 1.8318217675233686, 0.6501841494971068, 0.8085354286142143, 2.1349096473259586, 0.6118746771624517, 1.630695705034713, 1.3525064882663698, 1.092856323107968, 0.333872093171221, 0.27513957642002174, 184.5125, 0.0]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 274329 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    274329 non-null  float64\n",
      " 1   V1      274329 non-null  float64\n",
      " 2   V2      274329 non-null  float64\n",
      " 3   V3      274329 non-null  float64\n",
      " 4   V4      274329 non-null  float64\n",
      " 5   V5      274329 non-null  float64\n",
      " 6   V6      274329 non-null  float64\n",
      " 7   V7      274329 non-null  float64\n",
      " 8   V8      274329 non-null  float64\n",
      " 9   V9      274329 non-null  float64\n",
      " 10  V10     274329 non-null  float64\n",
      " 11  V11     274329 non-null  float64\n",
      " 12  V12     274329 non-null  float64\n",
      " 13  V13     274329 non-null  float64\n",
      " 14  V14     274329 non-null  float64\n",
      " 15  V15     274329 non-null  float64\n",
      " 16  V16     274329 non-null  float64\n",
      " 17  V17     274329 non-null  float64\n",
      " 18  V18     274329 non-null  float64\n",
      " 19  V19     274329 non-null  float64\n",
      " 20  V20     274329 non-null  float64\n",
      " 21  V21     274329 non-null  float64\n",
      " 22  V22     274329 non-null  float64\n",
      " 23  V23     274329 non-null  float64\n",
      " 24  V24     274329 non-null  float64\n",
      " 25  V25     274329 non-null  float64\n",
      " 26  V26     274329 non-null  float64\n",
      " 27  V27     274329 non-null  float64\n",
      " 28  V28     274329 non-null  float64\n",
      " 29  Amount  274329 non-null  float64\n",
      " 30  Class   274329 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284801    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 274329, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code which is fully written me and mentor\n",
    "\n",
    "def get_outliers(data , column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - IQR*1.5\n",
    "    upper_bound = Q3 + IQR*1.5\n",
    "    return [data.loc[(data[column].astype(float) < lower_bound) | (data[column].astype(float) > upper_bound)].shape[0] , lower_bound ,upper_bound]\n",
    "\n",
    "lowers , uppers = [] , []\n",
    "for col in df.columns:\n",
    "    lowers.append(get_outliers(df,col)[1])\n",
    "    uppers.append(get_outliers(df,col)[2])\n",
    "print(lowers)\n",
    "print(uppers)\n",
    "np.sum((df>lowers) & ( df<uppers),axis=1)>8\n",
    "df = df[np.sum((df>lowers) & ( df<uppers),axis=1)>23]\n",
    "df.info()\n",
    "df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_with_bounds(data):\n",
    "    for column in data.columns:\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        if column != \"Class\":\n",
    "            data[column] = np.where(data[column] < lower_bound, lower_bound, data[column])\n",
    "            data[column] = np.where(data[column] > upper_bound, upper_bound, data[column])\n",
    "    return data\n",
    "df = replace_outliers_with_bounds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     fig , (bfr , aft) = plt.subplots(nrows=1,ncols=2,figsize=(15,3))\n",
    "#     sns.histplot(df[col] , ax=bfr)\n",
    "#     sns.histplot(df[col].apply(np.log1p) , ax=aft)\n",
    "#     bfr.set(title= col)\n",
    "#     aft.set(title=\"Buda sonraki\")\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Class', 'Amount', 'V6', 'V17', 'V26', 'V20', 'V5', 'V10', 'V8', 'V4',\n",
      "       'V21', 'V27', 'V11', 'V9', 'V23', 'V13', 'V18', 'V22', 'V28', 'V7',\n",
      "       'Time', 'V19', 'V14', 'V2', 'V25', 'V16', 'V15', 'V3', 'V1', 'V24',\n",
      "       'V12'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_cols = df.dtypes[df.dtypes != \"object\"].index\n",
    "skewed_feats = df[num_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "skewed_feats =skewness[skewness>0.70].index\n",
    "for i in skewed_feats:\n",
    "    if i != \"Class\":\n",
    "        # print(np.min(df[i]),i)\n",
    "        df[i] +=5\n",
    "        # fig , (bfr,aft) = plt.subplots(ncols=2,nrows=1,figsize = (15,3))\n",
    "        # sns.histplot(df[i],ax=bfr)\n",
    "        df[i] , lam = boxcox(df[i])\n",
    "        # sns.histplot(df[i],ax=aft)\n",
    "        # plt.show()\n",
    "        # bfr.set(title= i)\n",
    "        # aft.set(title=\"Buda sonraki\")\n",
    "\n",
    "df.select_dtypes(include=\"O\").columns\n",
    "print(skewed_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0.041352159690537516\\n0.10495320475235947\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model qurmaq\n",
    "#logistic\n",
    "X_tr , X_te , Y_tr , Y_te  = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=0.2, random_state=42, shuffle=True)\n",
    "# pipelinelog = make_pipeline(StandardScaler(),LogisticRegression(random_state=42))\n",
    "\n",
    "# pipelinelog.fit(X_tr,Y_tr)\n",
    "\n",
    "# print(r2_score(Y_tr,pipelinelog.predict(X_tr)))\n",
    "# print(r2_score(Y_te,pipelinelog.predict(X_te)))\n",
    "\n",
    "\"\"\"\n",
    "0.041352159690537516\n",
    "0.10495320475235947\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00032818119248245736\n",
      "-0.0003464182179511166\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Bernoulli cunki Binarydi\n",
    "\n",
    "\n",
    "pipelinebay = Pipeline(steps=[('Scaler' ,StandardScaler()), ('model',BernoulliNB())])\n",
    "params = {'model__alpha':[0.1,0.5,1,5,10]}\n",
    "clf = GridSearchCV(pipelinebay, param_grid=params, cv=5, refit=True)\n",
    "clf.fit(X_tr, Y_tr)\n",
    "\n",
    "print(r2_score(Y_tr, clf.predict(X_tr)))\n",
    "print(r2_score(Y_te, clf.predict(X_te)))\n",
    "\n",
    "\n",
    "#As you can see naive bayes is way better for the data\n",
    "\"\"\"\n",
    "-0.00032818119248245736\n",
    "-0.0003464182179511166\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervisedLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
